{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyro-ppl in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.8.6)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyro-ppl) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyro-ppl) (3.3.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyro-ppl) (0.1.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyro-ppl) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyro-ppl) (4.66.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.11.0->pyro-ppl) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.11.0->pyro-ppl) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.11.0->pyro-ppl) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.11.0->pyro-ppl) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.11.0->pyro-ppl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.11.0->pyro-ppl) (2023.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm>=4.36->pyro-ppl) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from jinja2->torch>=1.11.0->pyro-ppl) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\baska\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sympy->torch>=1.11.0->pyro-ppl) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyro-ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network using Pyro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the code execution state was reset, let's redefine the classes and functions necessary to train the model.\n",
    "# After that, we'll attempt to train the model again.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from tqdm.auto import trange\n",
    "import time\n",
    "# Load the training data\n",
    "start_time = time.time()\n",
    "train_data = pd.read_csv('tests/train.csv')\n",
    "\n",
    "# Function to preprocess text data\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text.strip()\n",
    "\n",
    "# Preprocess the questions\n",
    "train_data['question1'] = train_data['question1'].astype(str).apply(preprocess)\n",
    "train_data['question2'] = train_data['question2'].astype(str).apply(preprocess)\n",
    "\n",
    "# Vectorize the questions using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X1 = vectorizer.fit_transform(train_data['question1'])\n",
    "X2 = vectorizer.transform(train_data['question2'])\n",
    "\n",
    "# Use the difference in TF-IDF vectors as features\n",
    "X_diff = X1 - X2\n",
    "y = train_data['is_duplicate'].values\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_diff.toarray(), dtype=torch.float)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float)\n",
    "print(X_tensor.shape)\n",
    "# Define the Bayesian Neural Network\n",
    "class Model(PyroModule):\n",
    "    def __init__(self, input_size, h1=20, h2=20):\n",
    "        super().__init__()\n",
    "        self.fc1 = PyroModule[nn.Linear](input_size, h1)\n",
    "        self.fc1.weight = PyroSample(dist.Normal(0., 1.).expand([h1, input_size]).to_event(2))\n",
    "        self.fc1.bias = PyroSample(dist.Normal(0., 1.).expand([h1]).to_event(1))\n",
    "        self.fc2 = PyroModule[nn.Linear](h1, h2)\n",
    "        self.fc2.weight = PyroSample(dist.Normal(0., 1.).expand([h2, h1]).to_event(2))\n",
    "        self.fc2.bias = PyroSample(dist.Normal(0., 1.).expand([h2]).to_event(1))\n",
    "        self.fc3 = PyroModule[nn.Linear](h2, 1)\n",
    "        self.fc3.weight = PyroSample(dist.Normal(0., 1.).expand([1, h2]).to_event(2))\n",
    "        self.fc3.bias = PyroSample(dist.Normal(0., 1.).expand([1]).to_event(1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        mu = self.fc3(x).squeeze(-1)\n",
    "        # sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))  # Changed to a larger range\n",
    "        # with pyro.plate(\"data\", x.shape[0]):\n",
    "        #     obs = pyro.sample(\"obs\", dist.Bernoulli(logits=mu), obs=y)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Bernoulli(logits=mu), obs=y)\n",
    "        return mu\n",
    "\n",
    "# Instantiate the model with the correct input size\n",
    "input_size = X_tensor.shape[1]\n",
    "model = Model(input_size)\n",
    "\n",
    "# Setup the guide and optimizer\n",
    "guide = AutoDiagonalNormal(model)\n",
    "adam = pyro.optim.Adam({\"lr\": 1e-3})\n",
    "svi = SVI(model, guide, adam, loss=Trace_ELBO())\n",
    "\n",
    "# The training loop\n",
    "pyro.clear_param_store()\n",
    "num_epochs = 1000  \n",
    "for epoch in trange(num_epochs):\n",
    "    loss = svi.step(X_tensor, y_tensor)\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss / (X_tensor.shape[0]*1000):.3f}\")\n",
    "    endtime = time.time()\n",
    "    print(\"total_time\",endtime-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_store_path = 'models/Pyro_NN_model.pyro'  # Replace with your path\n",
    "pyro.get_param_store().save(param_store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([199, 1837])\n",
      "Input tensor shape: torch.Size([199, 1837])\n",
      "Predictions have been saved to results/Pyro_NN_predictions.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.infer import Predictive\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('tests/test.csv')\n",
    "\n",
    "# Assuming that the 'preprocess' function and 'vectorizer' are already defined and fitted on the training data\n",
    "test_data['question1'] = test_data['question1'].astype(str).apply(preprocess)\n",
    "test_data['question2'] = test_data['question2'].astype(str).apply(preprocess)\n",
    "\n",
    "# # Vectorize the questions\n",
    "X1_test = vectorizer.transform(test_data['question1'])\n",
    "X2_test = vectorizer.transform(test_data['question2'])\n",
    "\n",
    "# Use the difference in TF-IDF vectors as features\n",
    "X_diff_test = X1_test - X2_test\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor_test = torch.tensor(X_diff_test.toarray(), dtype=torch.float)\n",
    "\n",
    "print(X_tensor_test.shape)\n",
    "print(f\"Input tensor shape: {X_tensor_test.shape}\")\n",
    "\n",
    "# Assuming that 'model' and 'guide' are already defined and trained\n",
    "try:\n",
    "    predictive = Predictive(model, guide=guide, num_samples=1000, return_sites=(\"obs\", \"_RETURN\"))\n",
    "    samples = predictive(X_tensor_test)\n",
    "    yhat = samples[\"obs\"].mean(0)  # Take the mean over all samples\n",
    "\n",
    "    # Convert predictions to binary labels\n",
    "    y_pred = (yhat > 0.5).int().numpy()\n",
    "except RuntimeError as e:\n",
    "    print(\"A runtime error occurred:\")\n",
    "    print(e)\n",
    "    # Inspect the shape of the parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Shape of {name}: {param.shape}\")\n",
    "    raise\n",
    "predictions_df = pd.DataFrame({\n",
    "    'question1': test_data['question1'],\n",
    "    'question2': test_data['question2'],\n",
    "    'predictions': y_pred\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predictions_df.to_csv('results/Pyro_NN_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions have been saved to results/Pyro_NN_predictions.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import trange\n",
    "import time\n",
    "start_time = time.time()\n",
    "# Load the training data\n",
    "train_data = pd.read_csv('tests/train.csv')\n",
    "\n",
    "# Function to preprocess text data\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text.strip()\n",
    "\n",
    "# Preprocess the questions\n",
    "train_data['question1'] = train_data['question1'].astype(str).apply(preprocess)\n",
    "train_data['question2'] = train_data['question2'].astype(str).apply(preprocess)\n",
    "\n",
    "# Vectorize the questions using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X1 = vectorizer.fit_transform(train_data['question1'])\n",
    "X2 = vectorizer.transform(train_data['question2'])\n",
    "\n",
    "# Use the difference in TF-IDF vectors as features\n",
    "X_diff = X1 - X2\n",
    "y = train_data['is_duplicate'].values\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_diff.toarray(), dtype=torch.float)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float)\n",
    "print(X_tensor.shape)\n",
    "\n",
    "# Define the Neural Network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, h1=20, h2=20):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x)).squeeze(-1)\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = X_tensor.shape[1]\n",
    "model = NeuralNetwork(input_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Create a DataLoader instance to handle batching\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "num_epochs = 1000  # Define the number of epochs for which the model will be trained\n",
    "\n",
    "# Training loop\n",
    "for epoch in trange(num_epochs):\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_function(y_pred, y_batch)/10\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch}: loss = {total_loss :.3f}\")\n",
    "    endtime = time.time()\n",
    "\n",
    "    print(\"total_time\",endtime-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's state dictionary has been saved to torch_model.pth.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'models/pytorch_NN_model.pth')\n",
    "print(\"The model's state dictionary has been saved to torch_model.pth.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been saved to results/pytorch_NN_predictions.csv.\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('tests/test.csv')\n",
    "\n",
    "# Preprocess and vectorize the test data\n",
    "test_data['question1'] = test_data['question1'].astype(str).apply(preprocess)\n",
    "test_data['question2'] = test_data['question2'].astype(str).apply(preprocess)\n",
    "X1_test = vectorizer.transform(test_data['question1'])\n",
    "X2_test = vectorizer.transform(test_data['question2'])\n",
    "X_diff_test = X1_test - X2_test\n",
    "X_tensor_test = torch.tensor(X_diff_test.toarray(), dtype=torch.float)\n",
    "\n",
    "# Predict the labels\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_tensor_test)\n",
    "    y_pred_binary = (y_pred > 0.5).int().numpy()\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'question1': test_data['question1'],\n",
    "    'question2': test_data['question2'],\n",
    "    'predictions': y_pred_binary\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predictions_df.to_csv('results/pytorch_NN_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions have been saved to results/pytorch_NN_predictions.csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
